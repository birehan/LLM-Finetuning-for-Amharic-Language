{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from util import Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dir = \"../data/cleaned\"\n",
    "final_dir = \"../data/final\"\n",
    "file_name = \"TIKVAH\"\n",
    "util = Util()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>symbols</th>\n",
       "      <th>links</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ታሪክ የሌለው ህዝብ ታሪካዊ ስራ ለመስራት አይጓጓም። ነፃነትም የማያውቅ ...</td>\n",
       "      <td>2017-07-27T11:37:49</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['tsegabwolde', 'tikvahethiopia']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ኢትዮጵያ ኣደይ !</td>\n",
       "      <td>2017-07-27T11:52:34</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['tikvahethiopia']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>አደራ ልጄ ገንዘብ ውርሴን አምጪ አትበይኝ አደራ መኪና ቪላ ፎቅ አትበይኝ...</td>\n",
       "      <td>2017-07-27T12:13:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ኢትዮጵያ ሀገሬ መመኪያ ነሽ ክብሬ !</td>\n",
       "      <td>2017-07-27T13:15:01</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['tikvahethiopia']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ኢትዮጵያዊነት ኢትዮጵያዊነት ብዙ የተለያዩ ህብረተሰቦች የተዋህዱበት አካል...</td>\n",
       "      <td>2017-07-27T13:37:46</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                 date  \\\n",
       "id                                                                           \n",
       "12  ታሪክ የሌለው ህዝብ ታሪካዊ ስራ ለመስራት አይጓጓም። ነፃነትም የማያውቅ ...  2017-07-27T11:37:49   \n",
       "14                                        ኢትዮጵያ ኣደይ !  2017-07-27T11:52:34   \n",
       "15  አደራ ልጄ ገንዘብ ውርሴን አምጪ አትበይኝ አደራ መኪና ቪላ ፎቅ አትበይኝ...  2017-07-27T12:13:05   \n",
       "17                            ኢትዮጵያ ሀገሬ መመኪያ ነሽ ክብሬ !  2017-07-27T13:15:01   \n",
       "18  ኢትዮጵያዊነት ኢትዮጵያዊነት ብዙ የተለያዩ ህብረተሰቦች የተዋህዱበት አካል...  2017-07-27T13:37:46   \n",
       "\n",
       "   hashtags emojis symbols links                           mentions  \n",
       "id                                                                   \n",
       "12       []    NaN     NaN    []  ['tsegabwolde', 'tikvahethiopia']  \n",
       "14       []    NaN     NaN    []                 ['tikvahethiopia']  \n",
       "15       []    NaN     NaN    []                                 []  \n",
       "17       []    NaN     NaN    []                 ['tikvahethiopia']  \n",
       "18       []    NaN       -    []                                 []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{cleaned_dir}/{file_name}.csv\", index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39754, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences into words using simple whitespace-based tokenizer\n",
    "tokenized_corpus = [str(sentence).lower().split() for sentence in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Word2Vec parameters\n",
    "embedding_size = 100 # Dimensionality of the embedding vector\n",
    "window_size = 5 # Context window size\n",
    "min_count = 5 # Minimum word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=embedding_size, window=window_size, min_count=min_count, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6796198 ,  1.9175681 ,  1.2038524 ,  0.9180412 , -2.6952844 ,\n",
       "       -2.0501866 ,  2.2284362 , -1.1628159 , -0.19251096,  0.1371436 ,\n",
       "        1.7825648 ,  1.3329823 ,  2.3856564 , -1.0559076 ,  0.808264  ,\n",
       "       -1.707025  ,  0.22677465, -1.3662279 ,  2.8594089 ,  2.6275942 ,\n",
       "       -0.60524416,  3.0606108 , -0.18936567,  0.46385664,  0.29130316,\n",
       "        1.3443623 , -3.184427  ,  1.3548936 , -1.6791693 , -1.3590449 ,\n",
       "        0.07344329, -0.61360514, -2.531398  ,  0.80191946,  2.4919195 ,\n",
       "        1.0340048 , -1.1296881 ,  1.9969218 , -3.527376  ,  1.5363679 ,\n",
       "        2.443714  , -3.3061233 , -4.2122607 ,  0.72669774, -2.3467135 ,\n",
       "       -0.34739316, -1.391667  , -1.4968252 , -0.5444341 , -1.3482528 ,\n",
       "        1.1990105 ,  1.1207374 ,  2.4027305 , -0.26652664,  0.89352924,\n",
       "       -0.5494331 , -0.07549217, -3.7299104 , -2.2069976 , -3.196344  ,\n",
       "       -1.9204704 ,  0.07365239,  0.3051049 ,  1.289145  ,  0.29336533,\n",
       "        0.16817036, -1.9856539 ,  2.5816116 , -1.2157148 ,  2.3950546 ,\n",
       "       -0.43824655, -1.7567328 , -0.762417  ,  2.5240233 , -3.023516  ,\n",
       "        0.20247833, -3.312539  , -1.4482359 ,  2.514327  ,  2.6137507 ,\n",
       "       -1.2198128 , -0.92001325,  1.1470468 ,  0.7807158 , -1.1845951 ,\n",
       "        0.8715687 ,  2.3681078 ,  1.114298  , -0.6029203 ,  0.26533532,\n",
       "        0.27005467,  0.01453162,  0.517058  ,  0.92879814,  1.8840079 ,\n",
       "        2.843285  ,  1.1901782 ,  0.28965336,  0.04992399, -2.9529839 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vector for a specific word\n",
    "vector = model.wv['ኢትዮጵያ'] #Ethiopia\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ኢትዮጵያም', 0.5789653062820435),\n",
       " ('አሜሪካ', 0.5713962316513062),\n",
       " ('ሱዳን', 0.5534135103225708),\n",
       " ('በኢትዮጵያ', 0.5501050353050232),\n",
       " ('ኢትዮጰያ', 0.5478282570838928)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similar words to a given word\n",
    "similar_words = model.wv.most_similar('ኢትዮጵያ', topn=5)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(f'{final_dir}/{file_name}_word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
